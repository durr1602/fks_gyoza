{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c573c0c",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# No parameters required"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8ac722-12d4-423e-b173-5ba897b4182c",
   "metadata": {},
   "source": [
    "# Growth curve analysis of validation mutants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11890dcb-5fe2-4621-b644-b216e282810f",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec072e2b-9a8f-4d99-bcdf-8daf296b98c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"svg.fonttype\"] = \"none\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edffbb3d-393f-4961-b010-5c09a4e44aa4",
   "metadata": {},
   "source": [
    "## Specify paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22c9445-cb76-491b-b0b7-5bd4d68b15ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "layout_path = \"../growth_data/20240129_full_layout.tsv\"\n",
    "source_data = [\n",
    "    \"../growth_data/20240128_validations_DMS_control.xlsx\",\n",
    "    \"../growth_data/20240128_validations_DMS_caspo.xlsx\",\n",
    "    \"../growth_data/20240131_validations_DMS_mica.xlsx\",\n",
    "    \"../growth_data/20240131_validations_DMS_ani.xlsx\",\n",
    "]\n",
    "DMS_data = \"../classified/BY4741_FKS1-HS1/refined_classification.csv\"\n",
    "\n",
    "# Output\n",
    "df_outpath = \"../growth_data/\"\n",
    "graph_outpath = \"../graphs/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78dcede-4e8b-461c-9744-bfafa9f469a2",
   "metadata": {},
   "source": [
    "## Get layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126d5095-80a7-48a0-8d50-4d9e0f7c98fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = pd.read_csv(\n",
    "    layout_path, sep=\"\\t\", header=0, dtype={\"Sanger_validated\": \"boolean\"}\n",
    ")\n",
    "layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9a5c9c-0a9e-4eb7-b96b-84cd79551ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Unique genotypes validated by Sanger:\\n\",\n",
    "    layout.loc[layout.Sanger_validated, \"genotype\"].unique(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e177b7-f44b-475a-b21c-b7510bc06aeb",
   "metadata": {},
   "source": [
    "## Get plate reader data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f488d429-8b10-49a4-b79d-ca0486a11936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(fpath):\n",
    "    ### Import libraries\n",
    "    import numpy as np\n",
    "    from datetime import datetime, date, time\n",
    "\n",
    "    ### Read excel file\n",
    "    source_df = pd.read_excel(fpath, index_col=0, header=0, skiprows=26, skipfooter=36)\n",
    "\n",
    "    ### Parse timepoints\n",
    "    t0, t1 = source_df.iloc[[0, 1], 0]  # Get the first and second timepoints\n",
    "\n",
    "    # Convert first timepoint from time (of the day) object to time duration (h)\n",
    "    t0_h = (\n",
    "        datetime.combine(date.today(), t0) - datetime.combine(date.today(), time.min)\n",
    "    ).total_seconds() / 3600\n",
    "\n",
    "    # Convert difference between second and first timepoint into duration in h (measurement interval)\n",
    "    delta = (\n",
    "        datetime.combine(date.today(), t1) - datetime.combine(date.today(), t0)\n",
    "    ).total_seconds() / 3600\n",
    "\n",
    "    # Rewrite column of timepoints using calculated values\n",
    "    source_df[\"Time\"] = np.arange(t0_h, t0_h + len(source_df.Time) * delta, delta)\n",
    "\n",
    "    # Delete column with temperature\n",
    "    source_df.drop(columns=\"TÂ° 600\", inplace=True)\n",
    "\n",
    "    # Rename columns\n",
    "    source_df.columns = [x.split(\"=\")[-1] if \"=\" in x else x for x in source_df.columns]\n",
    "\n",
    "    # Reshape\n",
    "    longdf = source_df.melt(\n",
    "        id_vars=\"Time\", var_name=\"well\", value_name=\"OD\"\n",
    "    )  # wide to long dataframe\n",
    "    return longdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c640b7-50e5-4ce7-90c9-96c8ac4ea849",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "\n",
    "for i, f in enumerate(source_data):\n",
    "    df = get_data(f)\n",
    "    df[\"plate\"] = i + 1\n",
    "    df_list.append(df)\n",
    "\n",
    "fulldf = pd.concat(df_list, ignore_index=True)\n",
    "fulldf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95adf0bd-dc80-4fd2-9c5a-0ce2a3fb14a1",
   "metadata": {},
   "source": [
    "## Annotate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a21413b-04ef-40e0-bdea-0d4a2dab09ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotdf = fulldf.merge(right=layout[layout.Sanger_validated], on=[\"plate\", \"well\"])\n",
    "annotdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a12666-026a-4df7-96a7-d825a8ade977",
   "metadata": {},
   "source": [
    "## Visualize growth curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344b4205-5b50-4753-8592-f8a59ec46e7a",
   "metadata": {},
   "source": [
    "```\n",
    "custom_params = {\"axes.spines.right\": False, \"axes.spines.top\": False}\n",
    "sns.set_theme(style=\"ticks\", rc=custom_params)\n",
    "\n",
    "grid = sns.FacetGrid(data=annotdf, col = 'compound', hue='genotype', palette='hls')\n",
    "grid.map(sns.lineplot, 'Time', 'OD')\n",
    "\n",
    "grid.set_titles(row_template='{row_name}', col_template='{col_name}')\n",
    "grid.set_axis_labels('Time (h)', 'OD')\n",
    "grid.add_legend(title = 'Genotype')\n",
    "grid.fig.subplots_adjust(top=0.9)\n",
    "grid.tight_layout()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cb2b1d-9d78-49da-8d1c-21001a8c16f2",
   "metadata": {},
   "source": [
    "## Calculate normalized area under the curve (AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b459857-127a-4c6d-a4ef-9674c3ff757d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auc(g):\n",
    "    import numpy as np\n",
    "\n",
    "    return np.trapezoid(g.OD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f046e8-ee58-4353-8087-8b0b4ac86317",
   "metadata": {},
   "outputs": [],
   "source": [
    "aucdf = (\n",
    "    annotdf[annotdf[\"Time\"] <= 40]\n",
    "    .groupby([\"genotype\", \"aa_seq\", \"clone\", \"compound\", \"well\"])[[\"OD\"]]\n",
    "    .apply(func=get_auc)\n",
    "    .reset_index(name=\"auc\")\n",
    ")\n",
    "aucdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9985a933-d095-4547-a609-6e34ae4b4fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggdf = (\n",
    "    aucdf.groupby([\"genotype\", \"aa_seq\", \"compound\"])[[\"auc\"]]\n",
    "    .agg(auc=(\"auc\", \"mean\"), auc_min=(\"auc\", \"min\"), auc_max=(\"auc\", \"max\"))\n",
    "    .reset_index()\n",
    ")\n",
    "aggdf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3162eb-4d9b-4fdf-be74-9bb6a8b538af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_l2fc(val, minv, maxv, comp, df):\n",
    "    import numpy as np\n",
    "\n",
    "    # Retrieve corresponding WT value for the condition\n",
    "    wt = df.loc[(df.compound == comp) & (df.genotype == \"BY\"), \"auc\"].values\n",
    "\n",
    "    # Make sure a single value was extracted\n",
    "    if len(wt) == 1:\n",
    "        # Return log2 fold-change for mean, min and max\n",
    "        return np.log2(val / wt[0]), np.log2(minv / wt[0]), np.log2(maxv / wt[0])\n",
    "    else:\n",
    "        return \"error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91424e3-73fa-49c3-98ca-5b0fa2c04210",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggdf[\"L2FC\"], aggdf[\"L2FC_min\"], aggdf[\"L2FC_max\"] = zip(\n",
    "    *aggdf.apply(\n",
    "        lambda row: get_l2fc(row.auc, row.auc_min, row.auc_max, row.compound, aggdf),\n",
    "        axis=1,\n",
    "    )\n",
    ")\n",
    "aggdf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d7b99b-709a-4891-8d62-147880380476",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aggdf[\"min_yerr\"] = aggdf[\"L2FC\"] - aggdf[\"L2FC_min\"]\n",
    "aggdf[\"max_yerr\"] = aggdf[\"L2FC_max\"] - aggdf[\"L2FC\"]\n",
    "aggdf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed06ef8c-3127-447f-8e59-096b953d7b83",
   "metadata": {},
   "source": [
    "## Visualize log2 fold changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063e30a3-e06d-49fc-8c17-79850df10987",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(aggdf, col=\"compound\", y=\"L2FC\", hue=\"genotype\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63868e7-8847-43c7-b1e3-32976d1514a3",
   "metadata": {},
   "source": [
    "## Compare with DMS scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c26605-1b99-4fe2-829c-54ef6fe3079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DMS_aa = pd.read_csv(DMS_data, index_col=0)\n",
    "DMS_aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0960aa-128f-4ab1-b38e-cb02afd186df",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrdf = aggdf.merge(right=DMS_aa, on=[\"compound\", \"aa_seq\"])\n",
    "corrdf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42df8035-f4ba-45b7-b987-d89872bb4394",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(\n",
    "    rc={\n",
    "        \"font.family\": \"Arial\",\n",
    "        \"font.size\": 8,\n",
    "        \"legend.title_fontsize\": 8,\n",
    "        \"legend.fontsize\": 8,\n",
    "        \"axes.labelsize\": 8,\n",
    "        \"axes.titlesize\": 8,\n",
    "        \"xtick.labelsize\": 8,\n",
    "        \"ytick.labelsize\": 8,\n",
    "        \"xtick.major.pad\": 2,\n",
    "        \"ytick.major.pad\": 2,\n",
    "        \"xtick.bottom\": True,\n",
    "        \"ytick.left\": True,\n",
    "        \"xtick.major.size\": 2,\n",
    "        \"ytick.major.size\": 2,\n",
    "    },\n",
    "    style=\"ticks\",\n",
    ")\n",
    "\n",
    "lcomp = [\"none\", \"anidulafungin\", \"caspofungin\", \"micafungin\"]\n",
    "comp_dict = {\n",
    "    \"caspofungin\": \"Caspofungin\",\n",
    "    \"micafungin\": \"Micafungin\",\n",
    "    \"anidulafungin\": \"Anidulafungin\",\n",
    "    \"none\": \"Control\",\n",
    "}\n",
    "classes = [\"resistant\", \"sensitive\", \"deleterious\"]\n",
    "class_palette = [\"#C75DAB\", \"#F1F1F1\", \"#009B9E\"]\n",
    "class_cmap = dict(zip(classes, class_palette))\n",
    "\n",
    "# Initialize list to save linear regression parameters for each condition\n",
    "reglist = []\n",
    "\n",
    "grid = sns.lmplot(\n",
    "    corrdf,\n",
    "    x=\"s\",\n",
    "    y=\"L2FC\",\n",
    "    col=\"compound\",\n",
    "    col_order=lcomp,\n",
    "    markers=\"none\",  # dots are redrawn with color = resistance class\n",
    "    # note: i've tried coloring the markers using scatter_kws, doesn't work\n",
    "    facet_kws={\"despine\": False},\n",
    "    line_kws={\"color\": \"lightgrey\"},\n",
    "    height=2,\n",
    "    aspect=0.9,\n",
    ")\n",
    "\n",
    "for i, c in enumerate(lcomp):\n",
    "    graphdf = corrdf[corrdf.compound == c]\n",
    "    grid.axes[0][i].title.set_text(comp_dict[c])\n",
    "\n",
    "    # Drawing error bars\n",
    "    grid.axes[0][i].errorbar(\n",
    "        x=graphdf.s,\n",
    "        y=graphdf.L2FC,\n",
    "        xerr=[graphdf.min_s, graphdf.max_s],\n",
    "        yerr=[graphdf.min_yerr, graphdf.max_yerr],\n",
    "        fmt=\"none\",\n",
    "        ecolor=\"grey\",  # only error bars, no dots\n",
    "    )\n",
    "\n",
    "    # Drawing dots, colored by their classification (resistant, WT-like, etc)\n",
    "    grid.axes[0][i].scatter(\n",
    "        x=graphdf.s,\n",
    "        y=graphdf.L2FC,\n",
    "        c=graphdf.sensres.map(class_cmap),\n",
    "        ec=\"grey\",\n",
    "        zorder=100,\n",
    "    )\n",
    "\n",
    "    # Calculate and display Spearman correlation coefficient\n",
    "    from scipy import stats\n",
    "\n",
    "    sr, sp = stats.spearmanr(graphdf.s, graphdf.L2FC)\n",
    "    grid.axes[0][i].text(\n",
    "        0.3, -0.5, rf\"$\\rho$ = {sr:.2f}\" + \"\\n$\\it{p}$-val = \" + f\"{sp:.1e}\", ha=\"left\"\n",
    "    )\n",
    "\n",
    "    # I am leaving some unused code below to compare linear regression with seaborn (statsmodels OLS) and sklearn\n",
    "    # but ultimately I use the regression done by seaborn (statsmodels OLS)\n",
    "    # then I fetch the slope and intercept from seaborn drawn lines and append them to a dataframe\n",
    "\n",
    "    # Perform linear regression using sklearn package\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "\n",
    "    X = graphdf.s.values.reshape(-1, 1)\n",
    "    y = graphdf.L2FC.values.reshape(-1, 1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=6\n",
    "    )  # train on 20% of dataset\n",
    "    reg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "    # Extract slope and intercept from sklearn Linear Regression model\n",
    "    slopeSK = reg.coef_.flatten()[0]\n",
    "    interceptSK = reg.intercept_[0]\n",
    "\n",
    "    # Extract slope and intercept from seaborn lmplot (statsmodels OLS)\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(\n",
    "        x=grid.axes[0][i].get_lines()[0].get_xdata(),\n",
    "        y=grid.axes[0][i].get_lines()[0].get_ydata(),\n",
    "    )\n",
    "\n",
    "    # Save slope and intercept for each condition in a list -> append to master list\n",
    "    reglist.append([c, slope, intercept])\n",
    "\n",
    "# Highlighting interesting cases\n",
    "int_mut = [\"V641W\", \"L642K\"]\n",
    "deviating_df = corrdf[\n",
    "    (corrdf.compound == \"micafungin\") & (corrdf.genotype.isin(int_mut))\n",
    "]\n",
    "grid.axes[0][3].scatter(\n",
    "    x=deviating_df.s,\n",
    "    y=deviating_df.L2FC,\n",
    "    c=deviating_df.sensres.map(class_cmap),\n",
    "    ec=\"k\",\n",
    "    lw=2,\n",
    "    zorder=200,\n",
    ")\n",
    "# .. and label them\n",
    "for i, m in enumerate(int_mut):\n",
    "    grid.axes[0][3].annotate(\n",
    "        m,\n",
    "        (deviating_df.s.values[i], deviating_df.L2FC.values[i]),  # x  # y\n",
    "        xytext=(-4, 0),  # distance of text label from xy coords\n",
    "        textcoords=\"offset fontsize\",  # xytext coords given in fontsize\n",
    "    )\n",
    "\n",
    "grid.set_axis_labels(\"DMS selection coefficient\", \"Log2FC(AUC)\")\n",
    "\n",
    "# Convert list of list to dataframe\n",
    "regdf = pd.DataFrame(reglist, columns=[\"compound\", \"slope\", \"intercept\"])\n",
    "\n",
    "plt.savefig(f\"{graph_outpath}/validations.svg\", format=\"svg\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8979637a-292f-4174-90d5-ce6c2841361f",
   "metadata": {},
   "outputs": [],
   "source": [
    "regdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaa5ad4-2920-4fe0-8cd2-048474b233c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_estimate_DMS_score(v, r, df):\n",
    "    # Merge row and dataframe containing linear regression parameters\n",
    "    merg = pd.merge(r.to_frame().T, df, how=\"left\", on=\"compound\")\n",
    "\n",
    "    # Get slope and intercept for this condition\n",
    "    s = merg.slope[0]\n",
    "    i = merg.intercept[0]\n",
    "\n",
    "    # Return corrected value\n",
    "    return (v - i) / s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a7f945-6968-4db3-8dbc-7ff50c26a51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutants for which we need to estimate the DMS score\n",
    "mut_no_DMS = [x for x in aggdf.genotype.unique() if x not in corrdf.genotype.unique()]\n",
    "print(mut_no_DMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4fbd1f-4499-4284-a594-f07a071bb8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggdf[\"s\"] = aggdf.apply(\n",
    "    lambda row: get_estimate_DMS_score(row.L2FC, row, regdf), axis=1\n",
    ")\n",
    "rescued_df = aggdf[aggdf.genotype.isin(mut_no_DMS + [\"V641W\", \"L642K\"])][\n",
    "    [\"compound\", \"genotype\", \"aa_seq\", \"s\"]\n",
    "]\n",
    "rescued_df[\"Nham_aa\"] = 1\n",
    "rescued_df[\"aa_pos\"] = rescued_df[\"genotype\"].map(lambda x: x[1:4])\n",
    "rescued_df[\"alt_aa\"] = rescued_df[\"genotype\"].map(lambda x: x[-1])\n",
    "rescued_df[\"wt_aa\"] = rescued_df[\"genotype\"].map(lambda x: x[0])\n",
    "rescued_df[[\"compound\", \"aa_seq\", \"Nham_aa\", \"aa_pos\", \"alt_aa\", \"wt_aa\", \"s\"]].to_csv(\n",
    "    f\"{df_outpath}/validation_DMS_missing_estimates.csv\", index=False\n",
    ")\n",
    "rescued_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd000c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Fks DMS analysis",
   "language": "python",
   "name": "fks_gyoza"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
